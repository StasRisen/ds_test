{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LinearRegression,Ridge, Lasso, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)\n",
    "X.columns = dataset.feature_names\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    train_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso и параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.71\n",
      "R2: 0.71\n",
      "R2: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_lr)\n",
    "print(f\"R2: {r2:.2f}\")\n",
    "\n",
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_ridge)\n",
    "print(f\"R2: {r2:.2f}\")\n",
    "\n",
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_lasso)\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчиrтайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "При GridSearch результаты R2 упали, RidgeCV похож, в LassoCV r2 улучшился"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10.0}\n",
      "0.5341051092937275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "model = Ridge()\n",
    "\n",
    "parameters = {\"alpha\":[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5]}\n",
    "Ridge_reg= GridSearchCV(model, parameters, scoring='r2',cv=5)\n",
    "\n",
    "result = Ridge_reg.fit(X_train, y_train)\n",
    "print(result.best_params_)\n",
    "print(result.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "0.5112232840698209\n"
     ]
    }
   ],
   "source": [
    "model = Lasso()\n",
    "\n",
    "parameters = {\"alpha\":[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5]}\n",
    "Lasso_reg= GridSearchCV(model, parameters, scoring='r2',cv=5)\n",
    "\n",
    "result = Lasso_reg.fit(X_train, y_train)\n",
    "print(result.best_params_)\n",
    "print(result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7065995399152001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RidgeCV([1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5], scoring='r2', cv=5)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7049260440433984"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LassoCV(alphas=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5], cv=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки(используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R2 ухудшился в lasso, сильнее всего в minmaxscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_ridge_minmax 0.70\n",
      "R2_ridge_st 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), Ridge())\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_ridge_minmax {r2:.2f}')\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_ridge_st {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_lasso_minmax 0.21\n",
      "R2_lasso_st 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), Lasso())\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_lasso_minmax {r2:.2f}')\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), Lasso())\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_lasso_st {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "R2 на minmax у ridgecv стал лучше. У LassoCV minmax стал существенно лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_ridge_minmax 0.71\n",
      "R2_ridge_st 0.71\n"
     ]
    }
   ],
   "source": [
    "reg = RidgeCV([1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5], scoring='r2', cv=5)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_ridge_minmax {r2:.2f}')\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_ridge_st {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_lasso_minmax 0.68\n",
      "R2_lasso_st 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "reg = LassoCV(alphas=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5], cv=5)\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_lasso_minmax {r2:.2f}')\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_lasso_st {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "На minmax Ridge сильно улучшился R2, на StScaler ухудшился. На лассо улучшились r2 во всех случаях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_ridge_minmax 0.78\n",
      "R2_ridge_st 0.53\n"
     ]
    }
   ],
   "source": [
    "reg = RidgeCV([1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5], scoring='r2', cv=5)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), poly, reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_ridge_minmax {r2:.2f}')\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), poly, reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_ridge_st {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_lasso_minmax 0.73\n",
      "R2_lasso_st 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "reg = LassoCV(alphas=[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5], cv=5)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), poly, reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_lasso_minmax {r2:.2f}')\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), poly, reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_lasso_st {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2. Напишите как изменился R2 по сравнению с предыдущими экспериментами"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Лучше всего Ridge с minmaxScaler, степенью полинома - 2, коэф.рег = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "R2_minmax 0.78\n",
      "{'alpha': 10.0}\n",
      "R2_st 0.53\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "parameters = {\"alpha\":[1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e+1, 1e+2, 1e+3, 1e+4, 1e+5]}\n",
    "reg= GridSearchCV(model, parameters, scoring='r2',cv=5)\n",
    "pipe = make_pipeline(MinMaxScaler(), poly, reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe[2].best_params_)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_minmax {r2:.2f}')\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), poly, reg)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(pipe[2].best_params_)\n",
    "\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2_st {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1 - больше 50К, 0 - меньше или равно 50К"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[14].loc[data[14] == '<=50K'] = 0\n",
    "data[14].loc[data[14] == '>50K'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[14]\n",
    "y= y.astype('int')\n",
    "X = data.drop(columns=[14])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#Пропусков нет, заменять вопросы буду в 14 задании\n",
    "#X_nan = X.replace([0,'?'], np.NaN)\n",
    "print(X.isnull().sum())\n",
    "#imp = SimpleImputer(strategy='most_frequent')\n",
    "#X_fill = imp.fit_transform(X_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import model_selection\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "# Use the ColumnTransformer to apply to the correct features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "result = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    result, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8338622172177296 0.8210298594639663\n"
     ]
    }
   ],
   "source": [
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(max_iter=100).fit(result,y)\n",
    "acc = cross_val_score(reg, result, y, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = cross_val_score(reg, result, y, scoring='f1', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8568796068796068 0.6665076335877863\n"
     ]
    }
   ],
   "source": [
    "print(acc.max(), f1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = SVC().fit(result,y)\n",
    "acc = cross_val_score(reg, result, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result, y, scoring='f1', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845004095004095 0.6318840579710144\n"
     ]
    }
   ],
   "source": [
    "print(acc.max(), f1.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8572891072891073 0.6645813282001924\n"
     ]
    }
   ],
   "source": [
    "reg = LinearSVC().fit(result,y)\n",
    "acc = cross_val_score(reg, result, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values='?',strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "# Use the ColumnTransformer to apply to the correct features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "result_1 = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score на новых данных. Напишите удалось ли улучшить результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8557534807534808 0.664922711058264\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression(max_iter=100).fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())\n",
    "#даже на 0.001 ухудшилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8428542178542179 0.6266407389402042\n"
     ]
    }
   ],
   "source": [
    "reg = SVC().fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())\n",
    "#уменшились значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8542178542178542 0.6570327552986512\n"
     ]
    }
   ],
   "source": [
    "reg = LinearSVC().fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())\n",
    "#уменшились значения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8569819819819819 0.6668256618173145\n",
      "0.845004095004095 0.6318840579710144\n",
      "0.8572891072891073 0.6645813282001924\n"
     ]
    }
   ],
   "source": [
    "X_nan = X.replace(['?'], np.NaN)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(missing_values='?',strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "# Use the ColumnTransformer to apply to the correct features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "result_1 = preprocessor.fit_transform(X_nan)\n",
    "\n",
    "reg = LogisticRegression(max_iter=100).fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())\n",
    "\n",
    "reg = SVC().fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())\n",
    "\n",
    "reg = LinearSVC().fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())\n",
    "\n",
    "#значения улучшились, если их просто удалить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 17. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8558558558558559 0.6733178654292343\n",
      "0.8658886158886159 0.6904315196998124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(missing_values='?',strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder())])\n",
    "\n",
    "# Use the ColumnTransformer to apply to the correct features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "\n",
    "result_1 = preprocessor.fit_transform(X_nan)\n",
    "\n",
    "reg = RandomForestClassifier().fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())\n",
    "\n",
    "reg = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=RANDOM_STATE).fit(result_1,y)\n",
    "acc = cross_val_score(reg, result_1, y, scoring='accuracy', cv=5)\n",
    "f1 = cross_val_score(reg, result_1, y, scoring='f1', cv=5)\n",
    "print(acc.max(), f1.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8658886158886159 0.6904315196998124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 1,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'random_state': 42,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(acc.max(), f1.max())\n",
    "reg.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
